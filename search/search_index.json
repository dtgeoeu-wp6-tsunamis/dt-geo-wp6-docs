{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to our DT-GEO WP6 Tsunamis documentation!","text":"<p>Here you can find some useful instructions on the tools and codes used by DT-GEO WP6 Tsunamis.</p>"},{"location":"#content","title":"Content","text":"<p>In this documentation you will find:   </p>"},{"location":"#spack-and-compss","title":"Spack and COMPSs","text":"<ul> <li>Run a pyCOMPSs job in a Spack environment on your local machine</li> <li>Run a pyCOMPSs job in a Spack environment on Galileo</li> <li>Run a pyCOMPSs job in a Spack environment on Leonardo</li> <li>Run a pyCOMPSs job in a Spack environment on Mercalli (work in progress)</li> <li>Spack and COMPSs - Cheat-sheet</li> <li>Spack and COMPSs - Troubleshooting</li> </ul>"},{"location":"#spack-for-ptf","title":"Spack for PTF","text":"<ul> <li>Create a Spack environment to run the PTF</li> </ul>"},{"location":"#tsunami-hysea","title":"Tsunami HySEA","text":"<ul> <li>Running Tsunami HySEA on Leonardo</li> <li>Running Tsunami HySEA inside a singularity container</li> <li>Tsunami HySEA - Troubleshooting</li> </ul>"},{"location":"#wp6-github","title":"WP6 GitHub","text":"<ul> <li>Upload and use docker images on GitHub WP6 page</li> </ul>"},{"location":"Tsunami-HySEA/container/","title":"Running Tsunami HySEA inside a singularity container on Leonardo","text":"<p>These instructions describe how to run Tsunami HySEA simulations inside a singularity container on Leonardo.   </p> <p>To run Tsunami HySEA inside a singularity container on Leonardo, you need:  1. The singularity image of HySEA and  2. A Spack environment with the same versions of openmpi and cuda used in the image   </p>"},{"location":"Tsunami-HySEA/container/#1-get-the-singularity-image-of-hysea","title":"1. Get the singularity image of HySEA","text":"<p>The singularity image of HySEA was created with the eFlows4HPC image service creation and can downloaded from their website, if you have an account.   </p> <p>Alternatively, the image can be found on Leonardo in the shared directory <code>/leonardo_work/DTGEO_T1_2/images</code> with the name <code>dt-geo_t-hysea_x86_64_openmpi_4.1.4_cuda_11.8_v_dt-geo.sif</code>.   </p> <p>Note that this image was created with specific versions of openmpi (4.1.4) and cuda (11.8) to match what is available on Leonardo. If you want to use different versions or use the image in a HPC cluster with a different architecture, then you need to create a new image.    </p>"},{"location":"Tsunami-HySEA/container/#2-create-and-activate-the-spack-environment","title":"2. Create and activate the Spack environment","text":"<p>Now we need to create a Spack environment with openmpi@4.1.4 and cuda@11.8. If you already have created a Spack environment to run HysEA on Leonardo outside a container, then you can simply activate that environment and move to the next point. If you don't have a Spack environment yet, you can either use an existing one, following the instructions in section 1 here or create a new one.    </p> <p>To create a new Spack environment:  <pre><code>module load spack\nmkdir envhysea\ncd envhysea\nspack env create -d .\nspack env activate -p .\nspack add openmpi@4.1.4+cuda\nspack concretize\nspack -d install\n</code></pre>  This will install openmpi, cuda, and other packages that have dependencies with openmpi. You can see the installed modules with the command <code>spack find</code>. At the moment of writing, the version of cuda installed with this method is 11.8 (cuda@11.8.89 in the output of <code>spack find</code>). If the version is different, then you have to specify the version of cuda you want to use (11.8) when creating the spack environment to fit the one that is installed in the singularity image.  </p> <p>Now you have a spack environment that you can activate any time you want with the command <code>spack env activate -p .</code>.      </p> Info <p>Here you can find some useful Spack commands.  </p>"},{"location":"Tsunami-HySEA/container/#3-run-hysea-inside-the-singularity-container","title":"3. Run HySEA inside the singularity container","text":"<p>Spack environment   Any time you want to run HySEA you need to activate the environment envhysea and load the openmpi module (which should automatically load also cuda).   <pre><code>module load spack\nspack env activate -p PATH-TO/envhysea\nspack load openmpi\n</code></pre> Singularity   To run HySEA inside a container we want to use SingularityPRO.   On Leonardo, both SingularityPRO and the normal version of Singularity are available. SingularityPRO is already installed in the system, so no action is needed to be able to use it, whereas the normal version of Singularity can be loaded as a module (<code>module load singularity</code>).   The benefit of using SingularityPRO instead of the normal Singularity is that SingularityPRO does not need a lot of memory to create the container from the image. Because the image we have of HySEA is quite large (&gt;8GB), when using the normal version of Singularity, you would need to reserve an entire node when submitting the job, even though you might want to use only 1 GPU inside that node. Therefore, it is better, and faster, to use SingularityPRO.   If you type <code>singularity --version</code> you should see this output <code>SingularityPRO version 3.9-9.el8</code>.    </p> <p>Copy test folder   Copy the directory <code>/leonardo_work/DTGEO_T1_2/testruns_hysea</code> into your home directory. Here you can find input files for HySEA and shell scripts to run some tests. </p> <p>Set the right paths   Open the file <code>runHySEA_singularity.sh</code> and write the full path to the testruns_hysea directory in this line:  <pre><code>mpirun singularity exec --nv --no-home --bind &lt;FULLPATH-TO-ROOT-OF&gt;/testruns_hysea:/testruns_hysea /leonardo_work/DTGEO_T1_2/images/dt-geo_t-hysea_x86_64_openmpi_4.1.4_cuda_11.8_v_dt-geo.sif testruns_hysea/run-inside-container.sh\n</code></pre>  Do not change the path after the colon symbol (:/testruns_hysea) as this is the path used inside the container.   </p> <p>Run 1 simulation   The first example is to run one simulation inside the singularity container. The input files for this simulation are inside the directory <code>BS_Scenario0001</code>.   </p> <p>To run the simulation, make sure you stand in the directory where the file <code>runHySEA_singularity.sh</code> is and have the spack environment active, then submit the job to the queue:  <pre><code>sbatch runHySEA_singularity.sh\n</code></pre>  What this script does is launching the command <code>mpirun singularity exec ... run-inside-container.sh</code>. This command executes the script run-inside-container.sh inside the container. This is where the commands <code>get_load_balancing</code> to create the grid and <code>TsunamiHySEA</code> are called.         The <code>--nv</code> flag is necessary because we want to use GPUs. The <code>--bind</code> flag is to mount the folder needed to run the simulation inside the container.    </p> <p>When the job is done, you should be able to see a file called <code>out_ts.nc</code> inside <code>BS_Scenario0001</code>.    </p> <p>Run 4 simulations   To run more than one simulation we use the files inside <code>Step2_BS</code>. Here there are 4 directories, each of them contains all the input files needed by HySEA. Note that in this example the grid created by <code>get_load_balancing</code> is already there.   Open the file <code>runHySEA_singularity.sh</code> and follow the instructions at the bottom of the file to ask for 4 GPUs instead of one and to use the right <code>mpirun singularity exec ...</code> call that mounts the Step2_BS directory.   </p> <p>Then submit the job to the queue:  <pre><code>sbatch runHySEA_singularity.sh\n</code></pre></p> <p>When the job is done, you should be able to see a file called <code>out_ts.nc</code> inside each subdirectory in <code>Step2_BS</code>.</p>"},{"location":"Tsunami-HySEA/container/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"},{"location":"Tsunami-HySEA/leonardo/","title":"Running Tsunami HySEA on Leonardo","text":"<p>These instructions describe how to set up a Spack environment on Leonardo to run Tsunami HySEA.   A compiled version of T-HySEA 3.9.0MC is available on Leonardo in the shared directory <code>/leonardo_work/DTGEO_T1_2/T-HySEA-leonardo</code>.    </p>"},{"location":"Tsunami-HySEA/leonardo/#1-create-the-spack-environment","title":"1. Create the Spack environment","text":"<ol> <li>Create a directory called <code>envhysea</code> in your home directory (or choose any location you prefer) and copy the spack.yaml file from the T-HySEA-leonardo directory: <pre><code>mkdir ~/envhysea\ncp /leonardo_work/DTGEO_T1_2/T-HySEA-leonardo/spack.yaml ~/envhysea\n</code></pre></li> <li>Load spack module and activate the environment: <pre><code>module load spack\nspack env activate -p ~/envhysea/\n</code></pre></li> <li>Install the modules specified in spack.yaml inside the environment: <pre><code>spack concretize\nspack -d install\n</code></pre> This might take a while. If everything worked fine, you should be able to see the installed modules with the command <code>spack find</code>.    </li> </ol> <p>Now you have a spack environment that you can activate any time you want with the commands in step 2. You do not need to repeat step 3 unless you change something in the spack.yaml file.     </p> Info <p>Here you can find some useful Spack commands.   </p>"},{"location":"Tsunami-HySEA/leonardo/#2-run-hysea","title":"2. Run HySEA","text":"<p>Any time you want to run HySEA you need to activate the environment envhysea and load the netcdf-c module.  <pre><code>module load spack\nspack env activate -p ~/envhysea/\nspack load netcdf-c\n</code></pre> Then you can use the executables get_load_balancing in T-HySEA_3.9.0_MC/bin_lb and TsunamiHySEA in T-HySEA_3.9.0_MC/bin. For example, if you have an input file called test-hysea.txt, you can do: <pre><code>/leonardo_work/DTGEO_T1_2/T-HySEA-leonardo/T-HySEA_3.9.0_MC/bin_lb/get_load_balancing test-hysea.txt 1 1\necho test-hysea.txt &gt; problems.txt\n</code></pre> Copy the script <code>run_hysea_spack.sh</code> to the directory where you want to launch the job from, check if you want to change anything in that file, then submit the job to the queue: <pre><code>cp /leonardo_work/DTGEO_T1_2/T-HySEA-leonardo/run_hysea_spack.sh &lt;/PATH-TO-WORK-DIR/&gt;\nsbatch run_hysea_spack.sh\n</code></pre></p>"},{"location":"Tsunami-HySEA/leonardo/#if-you-want-to-have-the-whole-repository-locally","title":"If you want to have the whole repository locally","text":"<p>If you prefer to have the whole repo in your home directory, then you can clone it with <pre><code>git clone git@github.com:dtgeoeu-wp6-tsunamis/T-HySEA-leonardo.git\n</code></pre> then follow the instructions above, starting from step 1.2 and using \"T-HySEA-leonardo\" instead of \"envhysea\".   </p>"},{"location":"Tsunami-HySEA/troubleshooting/","title":"Troubleshooting - Running HySEA","text":"<p>If you have problems with Spack, see this troubleshooting page</p>"},{"location":"Tsunami-HySEA/troubleshooting/#job-fails-error-when-converting-sif-file-to-temporary-sandbox","title":"Job fails - Error when converting SIF file to temporary sandbox","text":"<p>You might get an error while converting the HySEA image to temporary sandbox similar to this: <pre><code>INFO:    Converting SIF file to temporary sandbox...\nFATAL:   while extracting /PATH/images_singularity/dt-geo_t-hysea_x86_64_openmpi_4.1.4_cuda_11.8_v_dt-geo.sif: root filesystem extraction failed: extract command failed: WARNING: While bind mounting '/sbin/unsquashfs:/sbin/unsquashfs': destination is already in the mount point list\nWARNING: passwd file doesn't exist in container, not updating\n...\nParallel unsquashfs: Using 32 processors\n169807 inodes (311475 blocks) to write\n\n^M[=========\\                                                ]  53000/311475  17%^M[===============|                                          ]  83200/311475  26%: signal: killed\nslurmstepd: error: Detected 1 oom-kill event(s) in StepId=2003702.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.\n</code></pre></p> <p>This means that there is not enough memory for singularity to create the container. It also means that you are using the normal version of singularity instead of SingularityPRO.    There are two solutions (solution 2 is recommended):  1. Keep using the normal version of singularity, but add in your .sh script to submit the job the flag: <pre><code>#SBATCH --exclusive\n</code></pre> 2. Use SingularityPRO. To do that, check that you do not have the normal version of singularity loaded as a module (see output of <code>module list</code> and, if needed, do <code>module unload singularity</code>). Now you should be able to use the default version of singularity installed in the system, which is SingulairtyPRO. </p>"},{"location":"Tsunami-HySEA/troubleshooting/#job-fails-the-value-of-the-mca-parameter-plm_rsh_agent-was-set-to-a-path-that-could-not-be-found","title":"Job fails - The value of the MCA parameter \"plm_rsh_agent\" was set to a path that could not be found","text":"<p><pre><code>INFO:    Converting SIF file to temporary sandbox...\n--------------------------------------------------------------------------\nThe value of the MCA parameter \"plm_rsh_agent\" was set to a path\nthat could not be found:\n\n  plm_rsh_agent: ssh : rsh\n\nPlease either unset the parameter, or check that the path is correct\n--------------------------------------------------------------------------\n[lrdn3422.leonardo.local:650123] [[INVALID],INVALID] FORCE-TERMINATE AT Not found:-13 - error plm_rsh_component.c(335)\nINFO:    Cleaning up image...\n</code></pre> This is likely due to the fact that the spack environment and some environment variables are not automatically activated when the container starts.   To solve this issue, make sure you have this line as the first thing you do in the file with the list of commands to execute inside the container (e.g., run-inside-container.sh): <pre><code>source /etc/profile.d/z10_spack_environment.sh\n</code></pre></p>"},{"location":"WP6-github/upload_packages/","title":"Upload and use Docker images on GitHub WP6 page","text":"<p>GitHub provides detailed instructions on how to do load and use containers at the page Working with container registry. Since this page contains a lot of information, here, I describe step-by-step instructions that I used to upload a docker image on our WP6 page and how to pull an existing image.   </p>"},{"location":"WP6-github/upload_packages/#requirements","title":"Requirements","text":"<p>Both to upload and to use a docker image, you need to have Docker Desktop installed and an account on GitHub. To upload an image on our WP6 page, you also need to be a member of the WP6 organisation.</p>"},{"location":"WP6-github/upload_packages/#upload-your-docker-image","title":"Upload your docker image","text":"<p>Docker images are stored in the packages page of the WP6 GitHub organisation. By default, the image will be uploaded as \"private\", meaning that only people who are part of the WP6 GitHub page will be able to see it and use it, but, if desired, it can be changed to \"public\" after having uploaded it.   </p> <p>Assuming you already have a Docker image ready to be shared, below are the steps you need follow.   </p> <p>1. Generate a personal access token  First, you need to generate an access token with the scope of writing packages. Follow the instructions provided by GitHub.  At Step 8 of those instructions you will need to select the scope of the token you are generating. Select <code>write:packages</code>, which will automatically select also <code>read:packages</code>, and <code>delete:packages</code>.  Once you have generated your token, make sure to copy it somewhere, as it is needed at the next step.   </p> <p>2. Authenticate with your personal access token  Open a terminal and save your token in a variable:  <pre><code>export CR_PAT=YOUR_TOKEN\n</code></pre> where <code>YOUR_TOKEN</code> is the token you generated and copied at the previous step.  Now you can authenticate to the GitHub Container registry <code>ghcr.io</code> with the command:  <pre><code>echo $CR_PAT | docker login ghcr.io -u USERNAME --password-stdin\n</code></pre> If the login was successful, you should see the message <code>Login Succeeded</code>.   </p> <p>3. Name your docker image  The image that you will upload needs to have a name that contains the path of the registry (i.e., ghcr.io/dtgeoeu-wp6-tsunamis/image_name). If you have not built your image yet, you can build it directly with that name:  <pre><code>docker build -t ghcr.io/dtgeoeu-wp6-tsunamis/image_name .\n</code></pre></p> <p>However, if you have already an image, you can create a new one with the right name using the tag option. To do that, you need to know the Image ID of the existing image and then use the tag as follows:  <pre><code>docker tag imageID ghcr.io/dtgeoeu-wp6-tsunamis/image_name:latest\n</code></pre></p> <p>4. Upload the docker image  Now you can push the image to GitHub: <pre><code>docker push ghcr.io/dtgeoeu-wp6-tsunamis/image_name\n</code></pre> You should now be able to see your image in the list of packages of our WP6 packages page</p>"},{"location":"WP6-github/upload_packages/#pull-a-docker-image-from-github","title":"Pull a docker image from GitHub","text":"<p>You can pull any of the images loaded on our packages page with the <code>docker pull</code> command:  <pre><code>docker pull ghcr.io/dtgeoeu-wp6-tsunamis/image_name:latest\n</code></pre></p> <p>If you want to use singularity instead of Docker, you can download the docker image with the command: <pre><code>singularity pull --docker-login docker://ghcr.io/dtgeoeu-wp6-tsunamis/image_name:latest\n</code></pre> You will be asked to insert username and password.  A .sif file with the name of the image will be generated and stored in the folder from which you ran the command.  Note that not all docker images are directly convertible to singularity images and some tweaking might be needed to use them.   </p>"},{"location":"episode/purpose/","title":"Lecture title","text":"<p>Describe the lecture in high level language</p>"},{"location":"episode/purpose/#course-material","title":"Course material","text":"<p>Link to course presentation: fill in correct link  Link to repository : fill in correct link</p>"},{"location":"episode/purpose/#practicalities","title":"Practicalities","text":"<p>Target group: You would like to be involved (or start your own project) in coming and ongoing research projects and product development that involves machine learning</p> <p>Method: Classroom (with teams) lecture, live coding - presenter and participators, technical exercises</p> <p>Duration: 3 hours</p> <p>Language: Lecturing in English, coding mainly in Python</p> <p>Evaluation: Exam (with certificate) at the end of the series </p> <p>Course topics: In this course we will go through    - write my topics here</p>"},{"location":"episode/purpose/#prerequisites","title":"Prerequisites","text":"<p>To follow the content in this lecture you need to know   - Describe relevant courses taken before   - Familiarity with terminal   - Fill in more</p>"},{"location":"episode/purpose/#learning-objectives","title":"Learning objectives","text":"<p>After this course you will know:</p> <ul> <li>Write what you will know after the course</li> </ul>"},{"location":"episode/purpose/#credit","title":"Credit","text":"<p>This episode was developed by</p> <ul> <li>Creator(s): fill in name(s)</li> <li>Contributor(s): fill in name(s) </li> <li>Maintainers(s): fill in name(s)</li> </ul>"},{"location":"episode/set-up/","title":"Installation guide","text":"<p>Fill in relevant links to relevant tools descrined in the installation guide. </p>"},{"location":"episode/set-up/#tool-one","title":"Tool one","text":""},{"location":"episode/set-up/#tool-two","title":"Tool two","text":""},{"location":"episode/lectures/annotations-examples/","title":"Annotations","text":""},{"location":"episode/lectures/annotations-examples/#admonitions-in-annotations","title":"Admonitions in annotations","text":"<p>Phasellus posuere in sem ut cursus (1)</p> <p>Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> I'm an annotation!</li> <li> I'm an annotation as well!</li> </ol>"},{"location":"episode/lectures/code-examples/","title":"Working with code examples","text":""},{"location":"episode/lectures/code-examples/#example-with-lines-numbers","title":"Example with lines numbers","text":"turbine_model.py<pre><code>from typing import List\n\nfrom pydantic import BaseModel, Field\n\n\nclass SoilLayer(BaseModel):\n    depth: float = Field(description=\"Depth from seabed to soil later\")\n    number_of_elements: int = Field(\n        description=\"Number of elements of this material at this depth\"\n    )\n\nclass TurbineModel(BaseModel):\n    soil_layers: List[SoilLayer]\n    load_step_num: int = Field(\n         default=20, ge=0, description=\"Number of load steps in cycle\"\n    )    \n    # ... etc. for validation \n</code></pre>"},{"location":"episode/lectures/code-examples/#example-with-highlighted-lines","title":"Example with highlighted lines","text":"turbine_model.py<pre><code>from pydantic import BaseModel, Field\n\n\nclass SoilLayer(BaseModel):\n    depth: float = Field(description=\"Depth from seabed to soil later\")\n    number_of_elements: int = Field(\n        description=\"Number of elements of this material at this depth\"\n    )\n\nclass TurbineModel(BaseModel):\n    soil_layers: list[SoilLayer]\n    load_step_num: int = Field(\n         default=20, ge=0, description=\"Number of load steps in cycle\"\n    )    \n    # ... etc. for validation \n\nsoil_layers = [{\"depth\": 0, \"number_of_elements\": 2},{\"depth\":2, \"number_of_elements\": 3}]\nsimulation_steps = 20\nturbine_model = TurbineModel(\n        soil_layers=soil_layers,\n        load_step_num = simulation_steps\n    )\n\nprint(f\"My turbine model: {turbine_model}\")\n</code></pre>"},{"location":"episode/lectures/hands-on/","title":"Hands-on","text":"<p>Describe the point with the exercise in high level </p>"},{"location":"episode/lectures/hands-on/#exercise","title":"Exercise","text":""},{"location":"episode/lectures/icons/","title":"Icons","text":""},{"location":"episode/lectures/icons/#use-of-markdown-emojis","title":"Use of markdown emojis","text":"<p> +  =  </p>"},{"location":"episode/lectures/icons/#examples-of-admonitions","title":"Examples of admonitions","text":"<p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> Warning <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"episode/lectures/icons/#examples-of-tabs","title":"Examples of tabs","text":"Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol> <p>Example</p> Unordered ListOrdered List <pre><code>* Sed sagittis eleifend rutrum\n* Donec vitae suscipit est\n* Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"episode/lectures/icons/#admonitions-in-annotations","title":"Admonitions in annotations","text":"<p>Phasellus posuere in sem ut cursus (1)</p> <p>Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> I'm an annotation!</li> <li> I'm an annotation as well!</li> </ol>"},{"location":"episode/lectures/image-examples/","title":"How to include images","text":""},{"location":"episode/lectures/image-examples/#new-way-with-html-june-2023","title":"New way with html (June 2023)","text":"Caption"},{"location":"episode/lectures/image-examples/#old-way-with-tables","title":"Old way with tables","text":"Figure 1: Caption."},{"location":"spack-and-compss/cheat-sheet/","title":"Cheat sheet","text":""},{"location":"spack-and-compss/cheat-sheet/#useful-compss-commands","title":"Useful COMPSs commands","text":"<p>fill in more stuff here</p>"},{"location":"spack-and-compss/cheat-sheet/#useful-spack-commands","title":"Useful spack commands","text":"<p>Below is a short list of some useful commands. For the complete list of Spack commands check this link.      </p> Command Comment <code>spack env create -d .</code> To create a new environment in the current folder <code>spack env activate -p .</code> To activate an environment in the current folder <code>spack env deactivate</code> To deactivate the environment <code>spack list packagename</code> To see available packages that contain \"packagename\" on spack <code>spack info packagename</code> To see which versions of a specific package are available <code>spack add packagename</code> To add a new package (then do <code>spack concretize</code> and <code>spack install</code>) <code>spack add packagename@x.x.x</code> To add a new package, where x.x.x defines a specific version <code>spack install</code> To install packages added to the environment <code>spack load installed-package</code> To load a previously installed package in the environment* <code>spack find</code> To see what packages are installed in the environment <code>spack find --loaded</code> To see what packages are loaded in the environment <code>spack find --paths</code> To see where packages are installed within the spack environment <code>spack repo add /path/</code> To add a new repository (in addition to the default one from spack) <p>*Note that every time you activate an environemnt, the pacakges that are installed in there are not automatically loaded. So you need to do this 'spack load' command if you want to use a package.</p>"},{"location":"spack-and-compss/galileo/","title":"Run a pyCOMPSs job in a Spack environment on Galileo","text":"<p>These instructions describe how to set up a Spack environment that includes COMPSs and py-pip, and how to run a pyCOMPSs script on Galileo100.</p> Info <p>To know more about Spack and COMPSs:   Spack documentation COMPSs documentation</p>"},{"location":"spack-and-compss/galileo/#1-create-the-spack-environment","title":"1. Create the spack environment","text":"<ol> <li> <p>Load the spack module: <pre><code>module load spack\n</code></pre> This will load the version of Spack 0.17.1. The instructions below and the file spack.yaml are tested on this version of spack. Other versions of spack might work too, but the syntax in the spack.yaml file might be different.    </p> </li> <li> <p>Clone our repository. The <code>git submodule</code> command is to pull a secondary git repo within our main one.  <pre><code>git clone git@github.com:dtgeoeu-wp6-tsunamis/spack-compss.git\ncd spack-compss\ngit submodule update --init --recursive\n</code></pre></p> </li> <li> <p>Create and activate the Spack environment .  <pre><code>cd galileo/spackenv\nspack env create -d .\nspack env activate -p .\n</code></pre> Note that the -p flag is simply to visualize that the environment is active.</p> </li> <li> <p>The first time, you need to tell Spack where to find the compss package. This is done by adding a new spack repo. <pre><code>spack repo add /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/spack-dt-geo/var/spack/repos/builtin\n</code></pre></p> </li> <li>Install the packages specified in the spack.yaml file: <pre><code>spack concretize\nspack -d install\n</code></pre> Now you should have an environment with compss and py-pip installed. If something fails, check our troubleshooting guide.    </li> </ol> <p>You can do <code>spack find</code> to see which packages are now installed in the environment. To see if the installation of compss worked you can do <code>runcompss --version</code>, but the first time you do this you might need to deactivate the environment (<code>spack env deactivate</code>) and activate it again. If the command runcompss is not known, then something went wrong with the installation.   </p> <p>Once you have this basic environment set up, you can add and install more packages with <code>spack add packagename</code>, then repeating step 5.</p> Info <p>Here you can find some useful Spack commands.   </p>"},{"location":"spack-and-compss/galileo/#2-installing-python-packages-in-the-environment-optional","title":"2. Installing Python packages in the environment (optional)","text":"<p>You can use py-pip to install the python packages you need. Note that Spack already has many python packages available, but not all of them are included. Therefore, to be consistent, we have installed py-pip so that we can install the python packages with the pip install command. And because in the .yaml file we put the flag <code>concretization: together</code>, we are sure that COMPSs and pip will use the same python version.</p> <p>With the spack environment active, you can install any python package with pip: <pre><code>pip install name_of_python_package\n</code></pre> Or, if you have a requirements.txt file with a list of packages to install, you can do: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>If your python script needs to import local modules, then you need to add the directories where they can be found to the variable PYTHONPATH so that COMPSs knows where to look. For instance, if you have a folder /mycode/py/ with some routines that the main script needs to use, you need to set or update the PYTHONPATH to (make sure you write the full paths): <pre><code>export PYTHONPATH=$PYTHONPATH:/mycode:/mycode/py\n</code></pre></p>"},{"location":"spack-and-compss/galileo/#3-configure-compss-for-galileo","title":"3. Configure COMPSs for Galileo","text":"<p>Now we need to tell COMPSs which submission scripts to use that are specific for Galileo. This is defined by the two files g100.cfg and slurm.cfg, which we need to copy in the COMPSs folders of our Spack environment: <pre><code>cp galileo/g100.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/galileo/spackenv/.spack-env/view/compss/Runtime/scripts/queues/supercomputers/default.cfg   \ncp galileo/slurm.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/galileo/spackenv/.spack-env/view/compss/Runtime/scripts/queues/queue_systems/\n</code></pre></p>"},{"location":"spack-and-compss/galileo/#4-submit-a-job-on-galileo-with-enqueue_compss","title":"4. Submit a job on Galileo with enqueue_compss","text":"<p>The file <code>run_compss_galileo.sh</code> in the directory <code>galileo/</code> is an example of how to submit a job on Galileo with enqueue_compss. It is important to give the python_interpreter and pythonpath flags to make sure that compss uses the version of python inside the spack environment and that it knows the PYTHONPATH. </p> <ol> <li>Copy the example script to the directory you want to run the script from: <pre><code>cp galileo/run_compss_galileo.sh /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/run_compss.sh\n</code></pre></li> <li> <p>Open the file <code>run_compss.sh</code> and change the paths and name of the script to run.</p> </li> <li> <p>Activate the spack environment (if not activate yet) and load the modules needed to run the code: <pre><code>spack env activate -p /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/galileo/spackenv/\nspack load compss\n</code></pre></p> </li> <li>Submit the job with the spack environment active: <pre><code>cd /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/\n./run_compss.sh\n</code></pre></li> </ol>"},{"location":"spack-and-compss/galileo/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"},{"location":"spack-and-compss/leonardo/","title":"Run a pyCOMPSs job in a Spack environment on Leonardo","text":"<p>These instructions describe how to set up a Spack environment that includes COMPSs and py-pip, and how to run a pyCOMPSs script on Leonardo.</p> Info <p>To know more about Spack and COMPSs:   Spack documentation COMPSs documentation</p>"},{"location":"spack-and-compss/leonardo/#1-create-the-spack-environment","title":"1. Create the spack environment","text":"<ol> <li> <p>Load the spack module: <pre><code>module load spack\n</code></pre> This will load the version of Spack 0.19.1. The instructions below and the file spack.yaml are tested on this version of spack. Other versions of spack might work too, but the syntax in the spack.yaml file might be different. </p> </li> <li> <p>Clone our repository. The <code>git submodule</code> command is to pull a secondary git repo within our main one.  <pre><code>git clone git@github.com:dtgeoeu-wp6-tsunamis/spack-compss.git\ncd spack-compss\ngit submodule update --init --recursive\n</code></pre></p> </li> <li> <p>Create and activate the Spack environment .  <pre><code>cd leonardo/spackenv\nspack env create -d .\nspack env activate -p .\n</code></pre> Note that the -p flag is simply to visualize that the environment is active.</p> </li> <li> <p>The first time, you need to tell Spack where to find the compss package. This is done by adding a new spack repo. <pre><code>spack repo add /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/spack-dt-geo/var/spack/repos/builtin\n</code></pre></p> </li> <li>Install the packages specified in the spack.yaml file: <pre><code>spack concretize\nspack -d install\n</code></pre> Now you should have an environment with compss and py-pip installed. If something fails, check our troubleshooting guide.    </li> </ol> <p>You can do <code>spack find</code> to see which packages are now installed in the environment. To see if the installation of compss worked you can do <code>runcompss --version</code>, but the first time you do this you might need to deactivate the environment (<code>spack env deactivate</code>) and activate it again. If the command runcompss is not known, then something went wrong with the installation.   </p> <p>Once you have this basic environment set up, you can add and install more packages with <code>spack add packagename</code>, then repeating step 5.</p> Info <p>Here you can find some useful Spack commands.   </p>"},{"location":"spack-and-compss/leonardo/#2-installing-python-packages-in-the-environment-optional","title":"2. Installing Python packages in the environment (optional)","text":"<p>You can use py-pip to install the python packages you need. Note that Spack already has many python packages available, but not all of them are included. Therefore, to be consistent, we have installed py-pip so that we can install the python packages with the pip install command. And because in the .yaml file we put the flag <code>concretizer: unify: true</code>, we are sure that COMPSs and pip will use the same python version.</p> <p>With the spack environment active, you can install any python package with pip: <pre><code>pip install name_of_python_package\n</code></pre> Or, if you have a requirements.txt file with a list of packages to install, you can do: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>If your python script needs to import local modules, then you need to add the directories where they can be found to the variable PYTHONPATH so that COMPSs knows where to look. For instance, if you have a folder /mycode/py/ with some routines that the main script needs to use, you need to set or update the PYTHONPATH to (make sure you write the full paths): <pre><code>export PYTHONPATH=$PYTHONPATH:/mycode:/mycode/py\n</code></pre></p>"},{"location":"spack-and-compss/leonardo/#3-configure-compss-for-leonardo","title":"3. Configure COMPSs for Leonardo","text":"<p>Now we need to tell COMPSs which submission scripts to use that are specific for Leonardo. This is defined by the two files leonardo.cfg and slurm.cfg, which we need to copy in the COMPSs folders of our Spack environment: <pre><code>cp leonardo/leonardo.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/leonardo/spackenv/.spack-env/view/compss/Runtime/scripts/queues/supercomputers/default.cfg   \ncp leonardo/slurm.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/leonardo/spackenv/.spack-env/view/compss/Runtime/scripts/queues/queue_systems/\n</code></pre></p>"},{"location":"spack-and-compss/leonardo/#4-submit-a-job-on-leonardo-with-enqueue_compss","title":"4. Submit a job on Leonardo with enqueue_compss","text":"<p>The file <code>run_compss_leonardo.sh</code> in the directory <code>leonardo/</code> is an example of how to submit a job on Leonardo with enqueue_compss. It is important to give the python_interpreter and pythonpath flags to make sure that compss uses the version of python inside the spack environment and that it knows the PYTHONPATH. </p> <ol> <li>Copy the example script to the directory you want to run the script from: <pre><code>cp leonardo/run_compss_leonardo.sh /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/run_compss.sh\n</code></pre></li> <li> <p>Open the file <code>run_compss.sh</code> and change the paths and name of the script to run.</p> </li> <li> <p>Activate the spack environment (if not activate yet) and load the modules needed to run the code: <pre><code>spack env activate -p /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/leonardo/spackenv/\nspack load compss\n</code></pre></p> </li> <li>Submit the job with the spack environment active: <pre><code>cd /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/\n./run_compss.sh\n</code></pre></li> </ol>"},{"location":"spack-and-compss/leonardo/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"},{"location":"spack-and-compss/local/","title":"Run a pyCOMPSs job in a Spack environment on your local machine","text":"<p>These instructions describe how to set up a Spack environment that includes COMPSs and py-pip, and how to run a pyCOMPSs script on your local machine.</p> Info <p>To know more about Spack and COMPSs:   Spack documentation COMPSs documentation</p>"},{"location":"spack-and-compss/local/#1-download-spack-and-create-an-environment","title":"1. Download Spack and create an environment","text":"<p>Before installing Spack, check the system prerequisites that are needed to be present on your machine. Most of them are basic things that you likely already have (e.g., python&gt;3.6, C/C++ compilers, make, tar, git,...), but still worth checking the full list.</p> <ol> <li> <p>Choose the directory on your machine where you want to download Spack (&lt;FULLPATH-TO-SPACK-ROOT&gt;), then run the following commands:  <pre><code>cd /&lt;FULLPATH-TO-SPACK-ROOT&gt;\ngit clone --depth=100 --branch=releases/v0.17 https://github.com/spack/spack.git\n. /&lt;FULLPATH-TO-SPACK-ROOT&gt;/spack/share/spack/setup-env.sh\n</code></pre> Note that I use version 17.0 of Spack because it is the same version used on Galileo, but this can change. If you download a different version of Spack, some changes might be needed in the COMPSs and .yaml files.   </p> Tip <p>To avoid running the same command every time you open a new terminal, you might want to add this line to your ~/.bashrc file: <pre><code>. /&lt;FULLPATH-TO-SPACK-ROOT&gt;/spack/share/spack/setup-env.sh\n</code></pre></p> </li> <li> <p>Clone our repository. The <code>git submodule</code> command is to pull a secondary git repo within our main one. <pre><code>cd /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;\ngit clone git@github.com:dtgeoeu-wp6-tsunamis/spack-compss.git\ncd spack-compss\ngit submodule update --init --recursive\n</code></pre></p> </li> <li> <p>Copy the <code>compss</code> directory in spack-dt-geo to your local spack directory: <pre><code>cp -r spack-dt-geo/var/spack/repos/builtin/packages/compss /&lt;PATH-TO-SPACK-ROOT&gt;/spack/var/spack/repos/builtin/packages\n</code></pre></p> </li> <li> <p>Create and activate the Spack environment: <pre><code>cd spackenv\nspack env create -d .\nspack env activate -p .\n</code></pre> Note that the -p flag is simply to visualize that the environment is active.</p> </li> <li> <p>Install the packages specified in the spack.yaml file: <pre><code>spack concretize\nspack -d install\n</code></pre> Now you should have an environment with compss and py-pip installed. If something fails, check our troubleshooting guide.    </p> </li> </ol> <p>You can do <code>spack find</code> to see which packages are now installed in the environment. To see if the installation of compss worked you can do <code>runcompss --version</code>, but the first time you do this you might need to deactivate the environment (<code>spack env deactivate</code>) and activate it again. If the command runcompss is not known, then something went wrong with the installation.   </p> <p>Once you have this basic environment set up, you can add and install more packages with <code>spack add packagename</code>, then repeating step 5.</p> Info <p>Here you can find some useful Spack commands.   </p>"},{"location":"spack-and-compss/local/#2-installing-python-packages-in-the-environment-optional","title":"2. Installing Python packages in the environment (optional)","text":"<p>You can use py-pip to install the python packages you need. Note that Spack already has many python packages available, but not all of them are included. Therefore, to be consistent, we have installed py-pip so that we can install the python packages with the pip install command. And because in the .yaml file we put the flag <code>concretization: together</code>, we are sure that COMPSs and pip will use the same python version. With the spack environment active, you can install any python package with pip: <pre><code>pip install name_of_python_package\n</code></pre> Or, if you have a requirements.txt file with a list of packages to install, you can do: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>If your python script needs to import local modules, then you need to add the directories where they can be found to the variable PYTHONPATH so that COMPSs knows where to look. For instance, if you have a folder /mycode/py/ with some routines that the main script needs to use, you need to set or update the PYTHONPATH to (make sure you write the full paths): <pre><code>export PYTHONPATH=$PYTHONPATH:/mycode:/mycode/py\n</code></pre></p>"},{"location":"spack-and-compss/local/#3-configure-ssh-passwordless-access-to-your-machine","title":"3. Configure ssh passwordless access to your machine","text":"<p>Before running a pyCOMPSs script, you need to make sure that you can access your own local machine with ssh without password.  Full documentation about how COMPSs uses ssh and how to set it up can be found here.   </p> <ol> <li> <p>Check if this command works: <pre><code>ssh localhost\n</code></pre> If it works, then you go to the next section (4. Running a pyCOMPSs script) .   </p> </li> <li> <p>If <code>ssh localhost</code> did not work, then you need to setup a passwordless access to your own local machine.    If you do not have ssh installed and have never created a ssh public key, run the following commands (for Ubuntu):  <pre><code>apt install openssh-client openssh-server\nssh-keygen -t rsa\n</code></pre>  Note that ssh and ssh public keys are commonly used to access clusters or to use git, so it is likely that you already have it. If you do, then you do not need to run the two commands above. You can check if you have a ssh public key by checking if this file exists: .ssh/id_rsa.pub.   </p> </li> <li> <p>Copy the public key to the authorized keys file:   <pre><code>cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys\n</code></pre></p> </li> <li>Restart the terminal and check if ssh is running:  <pre><code>service ssh status\n</code></pre>  If not, start ssh service:  <pre><code>service ssh start\n</code></pre></li> <li>Check that you can access your own machine without password:  <pre><code>ssh localhost\n</code></pre></li> </ol>"},{"location":"spack-and-compss/local/#4-running-a-pycompss-script","title":"4. Running a pyCOMPSs script","text":"<p>Run a pyCOMPSs script with the spack environment active: <pre><code>runcompss --debug --python_interpreter=/&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spackenv/.spack-env/view/bin/python ./name_of_compss_script.py\n</code></pre> It is important to give the python_interpreter flag to make sure that compss uses the version of python inside the spack environment.</p>"},{"location":"spack-and-compss/local/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"},{"location":"spack-and-compss/mercalli/","title":"Run a pyCOMPSs job in a Spack environment on Mercalli","text":"<p>These instructions describe how to set up a Spack environment that includes COMPSs and py-pip, and how to run a pyCOMPSs script on Mercalli.</p> Warning <p>WORK IN PROGRESS: it works for queues with cpus, but not for the queue with gpus.</p> Info <p>To know more about Spack and COMPSs:   Spack documentation COMPSs documentation</p>"},{"location":"spack-and-compss/mercalli/#1-download-spack-and-create-an-environment","title":"1. Download Spack and create an environment","text":"<ol> <li> <p>Choose the directory on your machine where you want to download Spack (&lt;FULLPATH-TO-SPACK-ROOT&gt;), then run the following commands:  <pre><code>cd /&lt;FULLPATH-TO-SPACK-ROOT&gt;\ngit clone --depth=100 --branch=releases/v0.17 https://github.com/spack/spack.git\n. /&lt;FULLPATH-TO-SPACK-ROOT&gt;/spack/share/spack/setup-env.sh\n</code></pre> Note that I use version 17.0 of Spack because it is the same version used on Galileo, but this can change. If you download a different version of Spack, some changes might be needed in the COMPSs and .yaml files.   </p> Tip <p>To avoid running the same command every time you open a new terminal, you might want to add this line to your ~/.bashrc file: <pre><code>. /&lt;FULLPATH-TO-SPACK-ROOT&gt;/spack/share/spack/setup-env.sh\n</code></pre></p> </li> <li> <p>Clone our repository. The <code>git submodule</code> command is to pull a secondary git repo within our main one. <pre><code>cd /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;\ngit clone git@github.com:dtgeoeu-wp6-tsunamis/spack-compss.git\ncd spack-compss\ngit submodule update --init --recursive\n</code></pre></p> </li> <li> <p>Copy the <code>compss</code> directory in spack-dt-geo to your local spack directory: <pre><code>cp -r spack-dt-geo/var/spack/repos/builtin/packages/compss /&lt;PATH-TO-SPACK-ROOT&gt;/spack/var/spack/repos/builtin/packages\n</code></pre></p> </li> <li> <p>Create and activate the Spack environment: <pre><code>cd mercalli/spackenv\nspack env create -d .\nspack env activate -p .\n</code></pre> Note that the -p flag is simply to visualize that the environment is active.</p> </li> <li> <p>Install the packages specified in the spack.yaml file: <pre><code>spack concretize\nspack -d install\n</code></pre> Now you should have an environment with compss and py-pip installed. If something fails, check our troubleshooting guide.   </p> </li> </ol> <p>You can do <code>spack find</code> to see which packages are now installed in the environment. To see if the installation of compss worked you can do <code>runcompss --version</code>, but the first time you do this you might need to deactivate the environment (<code>spack env deactivate</code>) and activate it again. If the command runcompss is not known, then something went wrong with the installation.   </p> <p>Once you have this basic environment set up, you can add and install more packages with <code>spack add packagename</code>, then repeating step 5.</p> Info <p>Here you can find some useful Spack commands.   </p>"},{"location":"spack-and-compss/mercalli/#2-installing-python-packages-in-the-environment-optional","title":"2. Installing Python packages in the environment (optional)","text":"<p>You can use py-pip to install the python packages you need. Note that Spack already has many python packages available, but not all of them are included. Therefore, to be consistent, we have installed py-pip so that we can install the python packages with the pip install command. And because in the .yaml file we put the flag <code>concretization: together</code>, we are sure that COMPSs and pip will use the same python version. With the spack environment active, you can install any python package with pip: <pre><code>pip install name_of_python_package\n</code></pre> Or, if you have a requirements.txt file with a list of packages to install, you can do: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>If your python script needs to import local modules, then you need to add the directories where they can be found to the variable PYTHONPATH so that COMPSs knows where to look. For instance, if you have a folder /mycode/py/ with some routines that the main script needs to use, you need to set or update the PYTHONPATH to (make sure you write the full paths): <pre><code>export PYTHONPATH=$PYTHONPATH:/mycode:/mycode/py\n</code></pre></p>"},{"location":"spack-and-compss/mercalli/#3-configure-compss-for-mercalli","title":"3. Configure COMPSs for Mercalli","text":"<p>Now we need to tell COMPSs which submission scripts to use that are specific for Mercalli. This is defined by the two files mercalli_cpu.cfg and pbs_mercalli.cfg, which we need to copy in the COMPSs folders of our Spack environment: <pre><code>cp mercalli/mercalli_cpu.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/mercalli/spackenv/.spack-env/view/compss/Runtime/scripts/queues/supercomputers/   \ncp mercalli/pbs_mercalli.cfg /&lt;FULLPATH-TO-REPOSITORY-ROOT&gt;/spack-compss/mercalli/spackenv/.spack-env/view/compss/Runtime/scripts/queues/queue_systems/\n</code></pre></p> Warning <p>At the moment, this works only if you run the job in the queues on Mercalli with CPUs (not for the GPUs queue).</p>"},{"location":"spack-and-compss/mercalli/#4-submit-a-job-on-mercalli-with-enqueue_compss","title":"4. Submit a job on Mercalli with enqueue_compss","text":"<p>WORK IN PROGRESS FOR GPU QUEUE   </p> <p>The file <code>run_compss_mercalli_cpu.sh</code> in the directory <code>mercalli/</code> is an example of how to submit a job on Mercalli with enqueue_compss.       The file <code>myenv.sh</code> is used by compss to set the right environment variables in the computing nodes. In particular, JAVA_HOME needs to be specified there. The path to this file is then passed as a flag to enqueue_compss when we submit the job to the queue.   </p> <ol> <li>Copy the example scripts to the directory you want to run the script from: <pre><code>cp mercalli/run_compss_mercalli_cpu.sh /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/run_compss.sh\ncp mercalli/myenv.sh /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/\n</code></pre></li> <li> <p>Open the file <code>run_compss.sh</code> and change the paths (where you find 'fullpath') and name of the script to run. Some of the flags here are optional, but they might be useful. However, it is important to give the python_interpreter and pythonpath flags to make sure that compss uses the version of python inside the spack environment and that it knows the PYTHONPATH. And it is important to use the flag <code>--env_script</code> give the path to <code>myenv.sh</code>.      </p> </li> <li> <p>Open the file <code>myenv.sh</code> and set the right paths, especially for the variable JAVA_HOME.    </p> </li> <li> <p>Submit the job with the spack environment active: <pre><code>cd /&lt;PATH-TO-DIR-FOR-LAUNCHING-JOB&gt;/\n./run_compss.sh\n</code></pre></p> </li> </ol>"},{"location":"spack-and-compss/mercalli/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"},{"location":"spack-and-compss/troubleshooting/","title":"Troubleshooting - Spack + COMPSs","text":""},{"location":"spack-and-compss/troubleshooting/#compss-installation-fails","title":"COMPSs installation fails","text":"<p>This can be something related to the sha256. Check the log of the spack install command. If you ran it with the -d flag, you should be able to see an error that says that the sha256 has changed and it says which sha256 you should use now. If this is the case, you can copy that long combination of numbers and letters and paste it inside the file <code>/&lt;FULLPATH-TO-SPACK-COMPSS-REPO&gt;/var/spack/repos/builtin/packages/compss/package.py</code>. Then try <code>spack install</code> again.</p>"},{"location":"spack-and-compss/troubleshooting/#module-not-found-when-running-a-python-script-with-compss","title":"Module not found when running a python script with COMPSs","text":"<p>This could be related to pyCOMPSs not knowing where to look for the python routines defined bynthe user. Make sure you set up the variable $PYTHONPATH correctly. For instance, if you have a folder /mycode/py/ with some routines that the main script needs to use, you need to change the PYTHONPATH to (make sure you write the full paths): <pre><code>export PYTHONPATH=$PYTHONPATH:/mycode:/mycode/py\n</code></pre> If you are running a job on a cluster with the command <code>enqueue_compss</code>,  make sure you specify the PYTHONPATH with the flag --pythonpath</p>"},{"location":"spack-and-compss/troubleshooting/#problem-with-geos-cannot-find-libraries","title":"Problem with geos (cannot find libraries)","text":"<p>This error is specific for running the PTF. Even though geos is installed as a package in the spack environment, in some cases, it seems that python does not see it. Try <code>spack load geos</code> and run the PTF again.   </p>"},{"location":"spack-and-compss/troubleshooting/#job-submission-on-galileo-fails","title":"Job submission on Galileo fails","text":"<p>If the job submission fails and you get this error:  <code>/.../spackptf/.spack-env/view/compss/Runtime/scripts/queues/commons/submit.sh: line 19: bsub: command not found cat: /scratch_local/tmp.VJR55zlrin.err: No such file or directory    Error submiting script to queue system</code>  This is related to COMPSs using the wrong commands to submit a job to the queue in Galielo. Make sure you have copied the right configuration files specific for Galileo in the spack environment COMPSs folder, as described here.    </p>"},{"location":"spack-and-compss/troubleshooting/#installation-of-spack-environment-fails-problem-with-compilers","title":"Installation of Spack environment fails - Problem with compilers","text":"<p>If the installation of a spack environment fails, it can be because spack is using a version of the C compilers that have only gcc, but not g++. The error message would read something like \"Checking whether the C++ compiler supports templates ... configure: error: no\".  Open the spack.yaml file of the environment where the installation failed. There should be a section that Spack created called \"compilers\". Check what version of gcc is listed. If there is no path specified for some of the compilers (e.g., cxx), then you need to use a different version of gcc.</p> <p>In this case you can force spack to use the version of the compiler that has both gcc and g++. You can check what compilers you have available with the command <pre><code>spack compiler find\n</code></pre> The output is saved in a file called compilers.yaml (the path of this file is printed out by spack when you use the command above). Check the list of compilers. There should be at least one version of gcc that has paths for both gcc (cc) and g++ (cxx) compilers. Copy the entire section of the gcc compiler that has all the paths specified and paste it in the spack.yaml file (replacing what is already there). If your spack.yaml file did not have any compiler section, then just paste it at the bottom of the file. The spack.yaml file should look something like this:  <pre><code># This is a Spack Environment file.\n# It describes a set of packages to be installed, along with\n# configuration settings.\nspack:\n  # add package specs to the `specs` list\n  specs: [geos, py-pip, compss]\n  view: true\n  concretization: together\n  compilers:\n  - compiler:\n      paths:\n        cc: /usr/bin/gcc\n        cxx: /usr/bin/g++\n        f77: /usr/bin/gfortran\n        fc: /usr/bin/gfortran\n      operating_system: centos7\n      target: x86_64\n      modules: []\n      environment: {}\n      extra_rpaths: []\n      flags: {}\n      spec: gcc@4.8.5\n</code></pre></p>"},{"location":"spack-and-compss/troubleshooting/#updating-the-version-of-compss","title":"Updating the version of COMPSs","text":"<p>If a new version of COMPSs is released (note that the tag of the version might stay the same, e.g., 3.2, but the sha256 changes) and you want to update it in your spack environment, you need to follow these steps:   </p> <ul> <li> <p>Inside your spack environemnt, uninstall compss  <pre><code>spack uninstall compss\n</code></pre></p> </li> <li> <p>Clean the cache. This is needed otherwise spack will not fetch a new version of COMPSs because it sees that it has a version with the same tag (e.g., 3.2) in the cache  <pre><code>spack clean -m   \n</code></pre></p> </li> <li> <p>If you alread know the new sha256, then update it in the package.py file as exaplined here. If not, you should still follow the next steps, from which you will get an error message during the spack install that will give you the new sha256.   </p> </li> <li>Re-install compss and update the environment  <pre><code>spack add compss   \nspack concretize   \nspack -d install\n</code></pre></li> </ul> <p>It might be necessary to deactivate the environment and activate it again, before using it.  If you had some python pacakages installed with py-pip, it might also be necessary to re-install them. You can check with <code>pip list</code> if they are sill there or not.  If you are using Spack+COMPSs on a supercomputer, now that a new version of COMPSs is installed, the configuration files for running jobs with COMPSs are back to being the default ones and not anymore the ones specific for that supercomputer (e.g. Galileo). Therefore, you need to copy the configuration files again following the instructions here</p>"},{"location":"spack-for-ptf/local/","title":"Create a Spack environment to run the PTF","text":"<p>These instructions describe how to set up a Spack environment to run the PTF.</p> Info <p>To know more about Spack: Spack documentation Here you can find some useful Spack commands.  </p> <p>If you are running the PTF on an HPC cluster (e.g., Leonardo), it is likely that Spack is available as a module. If so, skip step 1, load the spack module, and go to step 2.  </p>"},{"location":"spack-for-ptf/local/#1-install-spack","title":"1. Install Spack","text":"<p>Before installing Spack, check the system prerequisites that are needed to be present on your machine. Most of them are basic things that you likely already have (e.g., python&gt;3.6, C/C++ compilers, make, tar, git,...), but still worth checking the full list.</p> <p>Choose the directory on your machine where you want to download Spack (&lt;FULLPATH-TO-SPACK-ROOT&gt;), then run the following commands:  <pre><code>cd /&lt;FULLPATH-TO-SPACK-ROOT&gt;\ngit clone -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n</code></pre> To avoid running the same command every time you open a new terminal, you might want to add this line to your ~/.bashrc file: <pre><code>. /&lt;FULLPATH-TO-SPACK-ROOT&gt;/spack/share/spack/setup-env.sh\n</code></pre></p>"},{"location":"spack-for-ptf/local/#2-create-an-environment","title":"2. Create an environment","text":"<p>Create and activate the Spack environment: <pre><code>spack env create -d spack_env_name\nspack env activate -p spack_env_name\n</code></pre> Note that the -p flag is simply to visualize that the environment is active.</p>"},{"location":"spack-for-ptf/local/#3-add-python-and-py-pip-to-the-environment-and-install-them","title":"3. Add Python and py-pip to the environment and install them","text":"<p><pre><code>spack add python\nspack add py-pip\nspack -d install\n</code></pre> In this way, the (last) preferred version of Python will be installed. In case you want to install a specific version, you can use the command <pre><code>spack info python\n</code></pre> and choose the version <pre><code>spack add pyhton@version\n</code></pre> Now you should have an environment with python and py-pip installed. You can do <code>spack find</code> to see which packages have been installed. If something failed, check our troubleshooting guide.    </p>"},{"location":"spack-for-ptf/local/#4-install-python-packages-needed-to-run-the-ptf-workflow-in-the-environment","title":"4. Install Python packages needed to run the PTF workflow in the environment","text":"<p>The required python packages are listed in the file <code>requirements.txt</code> which can be found in the tsunami-digital-twin repo or downloaded here.  Type the following command: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>A requirements file with specific versions of each python package installed with python 3.9.15 can be downloaded here.   </p> <p>Note that to install the python pacakge cartopy, GEOS needs to be installed as well. This is not a python package and it is possible that it is already installed locally. If so, then you do not need to do anything and the installation of cartopy should work. If, on the other hand, GEOS is not installed, then the installation of cartopy will fail. In this case, you can add GEOS as a spack package: <code>spack add geos</code>, then <code>spack install</code> </p>"},{"location":"spack-for-ptf/local/#problems","title":"Problems?","text":"<p>Check our troubleshooting guide.</p>"}]}